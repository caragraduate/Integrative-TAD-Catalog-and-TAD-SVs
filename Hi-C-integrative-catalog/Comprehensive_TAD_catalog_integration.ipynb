{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "technical-arrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "printable-syndication",
   "metadata": {},
   "source": [
    "## convert the IS boundary to TAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "handmade-survey",
   "metadata": {},
   "outputs": [],
   "source": [
    "## auto chr\n",
    "IS_5kb = pd.read_csv('data/inter30_5kb.robust_cutoff_boundaries_100kb.bed', sep='\\t', header = None)\n",
    "IS_5kbnew1 = IS_5kb.loc[:, [0, 1, 2]].copy()\n",
    "IS_5kbnew1.columns = ['chr','IS_start','IS_end']\n",
    "IS_5kbnew1['IS_start'] = IS_5kbnew1['IS_start']-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eligible-egyptian",
   "metadata": {},
   "outputs": [],
   "source": [
    "chr_size = pd.read_csv('data/hg38.chrom.sizes.bed', sep='\\t', header = None)\n",
    "invalid = ['chrX', 'chrY', 'chrMT']\n",
    "chr_size_new = chr_size[~chr_size[0].str.contains('|'.join(invalid))].copy()\n",
    "chr_size_new[0] = chr_size_new[0].str.replace('chr','').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fundamental-request",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the current working directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "directory = 'preprocess_data/'\n",
    "# Check if the directory exists\n",
    "if not os.path.exists(directory):\n",
    "    # Create the directory\n",
    "    os.makedirs(directory)\n",
    "\n",
    "# change the path to your own working directory\n",
    "os.chdir('preprocess_data/')\n",
    "for k, v in IS_5kbnew1.groupby('chr'):\n",
    "    v.to_csv(f'IS_boundary_start_end_chr{k}.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "creative-screening",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k in range (1,23):\n",
    "#     filename = 'IS_boundary_start_end_chr{}.csv'.format(k)\n",
    "#     boundary = pd.read_csv(filename, sep=',', header = 0)\n",
    "#     boundary = boundary.drop_duplicates()\n",
    "#     start = boundary[['chr', 'IS_end']]\n",
    "#     start_1 = start.iloc[:-1]\n",
    "#     start_1.reset_index(inplace = True, drop = True)\n",
    "#     end =  boundary[['IS_start']]\n",
    "#     end_1 = end.iloc[1:]\n",
    "#     end_1.reset_index(inplace = True, drop = True)\n",
    "#     result = pd.concat([start_1, end_1], axis=1)\n",
    "#     TAD1_end = boundary.iloc[0]['IS_start'].astype(int)\n",
    "#     df2 = pd.DataFrame({'chr': [k], 'IS_end' : ['0'], 'IS_start' : TAD1_end})\n",
    "#     TADlast_start = boundary.iloc[-1]['IS_end'].astype(int)\n",
    "#     TAD1ast_end = chr_size_new.loc[chr_size_new[0] == k, 1].item()\n",
    "#     df3 = pd.DataFrame({'chr': [k], 'IS_end' : TADlast_start, 'IS_start' : TAD1ast_end})\n",
    "#     dfnew = pd.concat([df2, result, df3], ignore_index = True, axis = 0)\n",
    "#     dfnew.columns = ['chr','TAD_start','TAD_end']\n",
    "#     out_file = 'IS_TAD_start_end_chr{}.bed'.format(k)\n",
    "#     dfnew.to_csv(out_file, index = False, sep='\\t', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "enclosed-genealogy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over chromosome numbers from 1 to 22\n",
    "for k in range(1, 23):\n",
    "    filename = f'IS_boundary_start_end_chr{k}.csv'\n",
    "    boundary = pd.read_csv(filename, sep=',', header=0).drop_duplicates()\n",
    "    start = boundary[['chr', 'IS_end']].iloc[:-1].reset_index(drop=True)\n",
    "    end = boundary[['IS_start']].iloc[1:].reset_index(drop=True)\n",
    "    result = pd.concat([start, end], axis=1)\n",
    "    TAD1_end = boundary.iloc[0]['IS_start'].astype(int)\n",
    "    df2 = pd.DataFrame({'chr': [k], 'IS_end': ['0'], 'IS_start': TAD1_end})\n",
    "    TADlast_start = boundary.iloc[-1]['IS_end'].astype(int)\n",
    "    TAD1ast_end = chr_size_new.loc[chr_size_new[0] == k, 1].item()\n",
    "    df3 = pd.DataFrame({'chr': [k], 'IS_end': TADlast_start, 'IS_start': TAD1ast_end})\n",
    "    dfnew = pd.concat([df2, result, df3], ignore_index=True)\n",
    "    dfnew.columns = ['chr', 'TAD_start', 'TAD_end']\n",
    "    out_file = f'IS_TAD_start_end_chr{k}.bed'\n",
    "    dfnew.to_csv(out_file, index=False, sep='\\t', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "horizontal-camcorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "root, dirs, files = next(os.walk(os.getcwd()))\n",
    "with open('all_IS_TAD_start_end.bed', 'a') as outfile:\n",
    "    for infile in files:\n",
    "        if infile.startswith('IS_TAD_start'):\n",
    "            df = pd.read_csv(os.path.join(root, infile), sep='\\t', skiprows=[0], header = None).drop_duplicates()\n",
    "            df.to_csv(outfile, index=False, sep='\\t', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "central-sterling",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = pd.read_csv('all_IS_TAD_start_end.bed', sep='\\t', header = None)\n",
    "f1new = f1[[0, 1, 2]].copy()\n",
    "f1new.columns = ['chr','TAD_start','TAD_end']\n",
    "f1new.sort_values(by=['chr', 'TAD_start'], inplace=True)\n",
    "f1new.to_csv('final_IS_TAD_start_end_5kb.bed', index=False, sep='\\t', header = True)\n",
    "f1new['length'] = f1new['TAD_end'] - f1new['TAD_start']\n",
    "f1new.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "floating-stomach",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate minimums in Pandas without `zero`-values\n",
    "f1new[f1new > 0].loc[:, 'length'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aware-nation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1new_nozero = f1new[(f1new['length'] > 0)]\n",
    "f1new_nozero['length'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "naked-document",
   "metadata": {},
   "outputs": [],
   "source": [
    "## for 5kb:\n",
    "# since min_TAD is 5000bp, which includes 1 bin\n",
    "# we set that exclude if there is any TAD includes >= 1 NA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accurate-voltage",
   "metadata": {},
   "source": [
    "### check if the IS_TAD includes NA insulation score regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "welcome-spank",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(current_directory)\n",
    "IS = pd.read_csv('data/inter30_5kb.insulation_100kb.bed', sep='\\t', header = None)\n",
    "ISnew = IS[[0, 1, 2, 4]].copy()\n",
    "ISnew.columns = ['chr','IS_start','IS_end','IS']\n",
    "ISnew['chr'] = ISnew['chr'].str.replace('chr','').astype(str)\n",
    "invalid = ['X', 'Y', 'MT']\n",
    "ISnew1 = ISnew.loc[~ISnew['chr'].str.contains('|'.join(invalid)), :].copy()\n",
    "ISnew1['chr'] = ISnew1['chr'].astype(int)\n",
    "ISnew1['IS'] = ISnew1['IS'].astype(str)\n",
    "IS_NA = ISnew1[ISnew1['IS'] == 'nan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "announced-kidney",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chr</th>\n",
       "      <th>IS_start</th>\n",
       "      <th>IS_end</th>\n",
       "      <th>IS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5001</td>\n",
       "      <td>10000</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>10001</td>\n",
       "      <td>15000</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>15001</td>\n",
       "      <td>20000</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20001</td>\n",
       "      <td>25000</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575005</th>\n",
       "      <td>22</td>\n",
       "      <td>50795001</td>\n",
       "      <td>50800000</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575006</th>\n",
       "      <td>22</td>\n",
       "      <td>50800001</td>\n",
       "      <td>50805000</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575007</th>\n",
       "      <td>22</td>\n",
       "      <td>50805001</td>\n",
       "      <td>50810000</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575008</th>\n",
       "      <td>22</td>\n",
       "      <td>50810001</td>\n",
       "      <td>50815000</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>575009</th>\n",
       "      <td>22</td>\n",
       "      <td>50815001</td>\n",
       "      <td>50818468</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35414 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        chr  IS_start    IS_end   IS\n",
       "0         1         1      5000  nan\n",
       "1         1      5001     10000  nan\n",
       "2         1     10001     15000  nan\n",
       "3         1     15001     20000  nan\n",
       "4         1     20001     25000  nan\n",
       "...     ...       ...       ...  ...\n",
       "575005   22  50795001  50800000  nan\n",
       "575006   22  50800001  50805000  nan\n",
       "575007   22  50805001  50810000  nan\n",
       "575008   22  50810001  50815000  nan\n",
       "575009   22  50815001  50818468  nan\n",
       "\n",
       "[35414 rows x 4 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IS_NA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grand-hotel",
   "metadata": {},
   "source": [
    "### find if the IS_TAD includes at least 10% of the length of the TADs are NA IS region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "joined-apache",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_chr_na(chr_i):   \n",
    "    filename = 'IS_TAD_start_end_chr{}.bed'.format(chr_i)\n",
    "    TAD = pd.read_csv(filename, sep='\\t', header = 0)\n",
    "    IS_nan = IS_NA[IS_NA.chr == chr_i] \n",
    "    overlap = pd.DataFrame(columns=['chr', 'TAD_start', 'TAD_end', 'IS'])\n",
    "    for start, end in zip(TAD.loc[:, 'TAD_start'], TAD.loc[:, 'TAD_end']):\n",
    "        temp_overlap = IS_nan[IS_nan.loc[:, 'IS_start'].between(start, end) | IS_nan.loc[:, 'IS_end'].between(start, end)]\n",
    "        if temp_overlap.shape[0] >= 1:\n",
    "            temp_overlap2 = temp_overlap.copy(deep = True)\n",
    "            temp_overlap2['chr'] = IS_nan.loc[:, 'chr']\n",
    "            temp_overlap2['TAD_start'] = start\n",
    "            temp_overlap2['TAD_end'] = end\n",
    "            temp_overlap2['IS'] = IS_nan.loc[:, 'IS']\n",
    "            temp_overlap2['num_NA'] = int(temp_overlap.shape[0])\n",
    "            temp_overlap2['num_NA'] = temp_overlap2['num_NA']\n",
    "            overlap = pd.concat([overlap, temp_overlap2], axis=0).astype(str)\n",
    "\n",
    "    ### overlap file\n",
    "    final = overlap[['chr', 'TAD_start', 'TAD_end', 'IS', 'num_NA']].drop_duplicates()\n",
    "    final['length'] = final['TAD_end'].astype(int) - final['TAD_start'].astype(int)\n",
    "    #final['include_NA'] = final['lenth'].astype(int)//5000\n",
    "    out_file = 'NA_TAD_IS_start_end_chr{}.bed'.format(chr_i)\n",
    "    final.to_csv(out_file, index = False, sep='\\t', header=True)\n",
    "    \n",
    "    final_larger = final[final['num_NA'].astype(float).astype(int)*5000 > (final['length']//10).astype(int)]\n",
    "    out_file_1 = 'NA_larger_incluna_TAD_IS_start_end_chr{}.bed'.format(chr_i)\n",
    "    final_larger.to_csv(out_file_1, index = False, sep='\\t', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "daily-attachment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0770 s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "os.chdir('preprocess_data/')\n",
    "start = time.time()\n",
    "all_data = Parallel(n_jobs=40)(delayed(all_chr_na)(chr_i) for chr_i in range(1,23))\n",
    "end = time.time()\n",
    "print('{:.4f} s'.format(end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpha-degree",
   "metadata": {},
   "source": [
    "### remove the NA_TAD from the all_TAD result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "committed-lighter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_chr_nona(chr_i):   \n",
    "    filename = 'IS_TAD_start_end_chr{}.bed'.format(chr_i)\n",
    "    TAD = pd.read_csv(filename, sep='\\t', header = 0)\n",
    "    filename_1 = 'NA_larger_incluna_TAD_IS_start_end_chr{}.bed'.format(chr_i)\n",
    "    IS_nan = pd.read_csv(filename_1, sep='\\t', header = 0, usecols=range(3))\n",
    "    final = pd.concat([TAD, IS_nan]).drop_duplicates(keep=False)\n",
    "    out_file = 'noNA_TAD_IS_start_end_chr{}.bed'.format(chr_i)\n",
    "    final.to_csv(out_file, index = False, sep='\\t', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "warming-religion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4093 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "all_data = Parallel(n_jobs=40)(delayed(all_chr_nona)(chr_i) for chr_i in range(1,23))\n",
    "end = time.time()\n",
    "print('{:.4f} s'.format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "filled-sierra",
   "metadata": {},
   "outputs": [],
   "source": [
    "root, dirs, files = next(os.walk(os.getcwd()))\n",
    "with open('all_noNA_IS_TAD_start_end.bed', 'a') as outfile:\n",
    "    for infile in files:\n",
    "        if infile.startswith('noNA_TAD_IS'):\n",
    "            df = pd.read_csv(os.path.join(root, infile), sep='\\t', skiprows=[0], header = None).drop_duplicates()\n",
    "            df.to_csv(outfile, index=False, sep='\\t', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "abstract-biotechnology",
   "metadata": {},
   "outputs": [],
   "source": [
    "f2 = pd.read_csv('all_noNA_IS_TAD_start_end.bed', sep='\\t', header = None)\n",
    "f2new = f2[[0,1,2]].copy()\n",
    "f2new.columns = ['chr','TAD_start','TAD_end']\n",
    "f2new.sort_values(by=['chr', 'TAD_start'], inplace=True)\n",
    "f2new['length'] = f2new['TAD_end'] - f2new['TAD_start']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "brilliant-midwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "### exclude the TAD with zero length\n",
    "f2new_nozero = f2new[(f2new['length'] > 0)]\n",
    "f2new_nozero.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "radio-grenada",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7265000"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f2new_nozero['length'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "specific-maria",
   "metadata": {},
   "outputs": [],
   "source": [
    "f2new_nozero.to_csv('final_noNA_IS_TAD_start_end_5kb.bed', index=False, sep='\\t', header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prerequisite-garage",
   "metadata": {},
   "source": [
    "### find the TADs that converted from IS but not having maxima "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "close-cologne",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 'chr' prefix to each entry in the 'chr' column to get the IN_TAD with no NA\n",
    "f2new_nozero = f2new_nozero.copy()\n",
    "f2new_nozero['chr'] = 'chr' + f2new_nozero['chr'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "known-mainstream",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chr</th>\n",
       "      <th>TAD_start</th>\n",
       "      <th>TAD_end</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr1</td>\n",
       "      <td>870000</td>\n",
       "      <td>975000</td>\n",
       "      <td>105000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chr1</td>\n",
       "      <td>980000</td>\n",
       "      <td>1110000</td>\n",
       "      <td>130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chr1</td>\n",
       "      <td>1115000</td>\n",
       "      <td>1300000</td>\n",
       "      <td>185000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chr1</td>\n",
       "      <td>1305000</td>\n",
       "      <td>1370000</td>\n",
       "      <td>65000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chr1</td>\n",
       "      <td>1375000</td>\n",
       "      <td>1510000</td>\n",
       "      <td>135000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14437</th>\n",
       "      <td>chr22</td>\n",
       "      <td>50045000</td>\n",
       "      <td>50135000</td>\n",
       "      <td>90000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14438</th>\n",
       "      <td>chr22</td>\n",
       "      <td>50140000</td>\n",
       "      <td>50240000</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14439</th>\n",
       "      <td>chr22</td>\n",
       "      <td>50245000</td>\n",
       "      <td>50345000</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14440</th>\n",
       "      <td>chr22</td>\n",
       "      <td>50350000</td>\n",
       "      <td>50505000</td>\n",
       "      <td>155000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14441</th>\n",
       "      <td>chr22</td>\n",
       "      <td>50510000</td>\n",
       "      <td>50625000</td>\n",
       "      <td>115000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14442 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         chr  TAD_start   TAD_end  length\n",
       "0       chr1     870000    975000  105000\n",
       "1       chr1     980000   1110000  130000\n",
       "2       chr1    1115000   1300000  185000\n",
       "3       chr1    1305000   1370000   65000\n",
       "4       chr1    1375000   1510000  135000\n",
       "...      ...        ...       ...     ...\n",
       "14437  chr22   50045000  50135000   90000\n",
       "14438  chr22   50140000  50240000  100000\n",
       "14439  chr22   50245000  50345000  100000\n",
       "14440  chr22   50350000  50505000  155000\n",
       "14441  chr22   50510000  50625000  115000\n",
       "\n",
       "[14442 rows x 4 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f2new_nozero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "actual-diary",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(current_directory)\n",
    "IS_TAD_containMaxima = pd.read_csv('data/noNA_IS_TAD_containsMaxima.bed', sep='\\t', header=None)\n",
    "IS_TAD_containMaxima.columns = ['#chr', 'TAD_start', 'TAD_end', 'length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "overall-advice",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_maxima = pd.concat([f2new_nozero, IS_TAD_containMaxima]).drop_duplicates(keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ranking-phrase",
   "metadata": {},
   "outputs": [],
   "source": [
    "## delete the duplicate overlap_IS_12878"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "supposed-billion",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap = pd.read_csv('data/overlap_IS_arrow_new_maxima.bed', sep='\\t', header = None)\n",
    "overlap.sort_values(by=[0, 1], inplace=True)\n",
    "#overlap\n",
    "# df = overlap.drop_duplicates(subset=[0,1,2], keep='last')\n",
    "overlap.columns = [\"IS_chr\", \"IS_Start\", \"IS_End\", \"IS_TAD_length\", \"#chr\", \"TAD_start\", \"TAD_end\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "confidential-static",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IS_chr</th>\n",
       "      <th>IS_Start</th>\n",
       "      <th>IS_End</th>\n",
       "      <th>IS_TAD_length</th>\n",
       "      <th>#chr</th>\n",
       "      <th>TAD_start</th>\n",
       "      <th>TAD_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3804</th>\n",
       "      <td>chr1</td>\n",
       "      <td>870000</td>\n",
       "      <td>975000</td>\n",
       "      <td>105000</td>\n",
       "      <td>chr1</td>\n",
       "      <td>885000</td>\n",
       "      <td>970000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4134</th>\n",
       "      <td>chr1</td>\n",
       "      <td>980000</td>\n",
       "      <td>1110000</td>\n",
       "      <td>130000</td>\n",
       "      <td>chr1</td>\n",
       "      <td>980000</td>\n",
       "      <td>1070000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>chr1</td>\n",
       "      <td>1115000</td>\n",
       "      <td>1300000</td>\n",
       "      <td>185000</td>\n",
       "      <td>chr1</td>\n",
       "      <td>980000</td>\n",
       "      <td>1305000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>chr1</td>\n",
       "      <td>1375000</td>\n",
       "      <td>1510000</td>\n",
       "      <td>135000</td>\n",
       "      <td>chr1</td>\n",
       "      <td>1320000</td>\n",
       "      <td>1510000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1074</th>\n",
       "      <td>chr1</td>\n",
       "      <td>1750000</td>\n",
       "      <td>1915000</td>\n",
       "      <td>165000</td>\n",
       "      <td>chr1</td>\n",
       "      <td>1760000</td>\n",
       "      <td>1905000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8686</th>\n",
       "      <td>chr9</td>\n",
       "      <td>136950000</td>\n",
       "      <td>137040000</td>\n",
       "      <td>90000</td>\n",
       "      <td>chr9</td>\n",
       "      <td>136945000</td>\n",
       "      <td>137035000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8687</th>\n",
       "      <td>chr9</td>\n",
       "      <td>137115000</td>\n",
       "      <td>137245000</td>\n",
       "      <td>130000</td>\n",
       "      <td>chr9</td>\n",
       "      <td>137085000</td>\n",
       "      <td>137245000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8688</th>\n",
       "      <td>chr9</td>\n",
       "      <td>137305000</td>\n",
       "      <td>137410000</td>\n",
       "      <td>105000</td>\n",
       "      <td>chr9</td>\n",
       "      <td>137310000</td>\n",
       "      <td>137405000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8689</th>\n",
       "      <td>chr9</td>\n",
       "      <td>137460000</td>\n",
       "      <td>137540000</td>\n",
       "      <td>80000</td>\n",
       "      <td>chr9</td>\n",
       "      <td>137450000</td>\n",
       "      <td>137540000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8690</th>\n",
       "      <td>chr9</td>\n",
       "      <td>137670000</td>\n",
       "      <td>137865000</td>\n",
       "      <td>195000</td>\n",
       "      <td>chr9</td>\n",
       "      <td>137665000</td>\n",
       "      <td>137795000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8902 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     IS_chr   IS_Start     IS_End  IS_TAD_length  #chr  TAD_start    TAD_end\n",
       "3804   chr1     870000     975000         105000  chr1     885000     970000\n",
       "4134   chr1     980000    1110000         130000  chr1     980000    1070000\n",
       "545    chr1    1115000    1300000         185000  chr1     980000    1305000\n",
       "780    chr1    1375000    1510000         135000  chr1    1320000    1510000\n",
       "1074   chr1    1750000    1915000         165000  chr1    1760000    1905000\n",
       "...     ...        ...        ...            ...   ...        ...        ...\n",
       "8686   chr9  136950000  137040000          90000  chr9  136945000  137035000\n",
       "8687   chr9  137115000  137245000         130000  chr9  137085000  137245000\n",
       "8688   chr9  137305000  137410000         105000  chr9  137310000  137405000\n",
       "8689   chr9  137460000  137540000          80000  chr9  137450000  137540000\n",
       "8690   chr9  137670000  137865000         195000  chr9  137665000  137795000\n",
       "\n",
       "[8902 rows x 7 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "other-weapon",
   "metadata": {},
   "source": [
    "### find the TADs that arrowhead detected but IS did not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "chief-railway",
   "metadata": {},
   "outputs": [],
   "source": [
    "## retrieve the regions that both arrow and IS detected but arrow has subTADs within it (detected more than one TAD)\n",
    "overlap_subTADs = overlap[overlap.duplicated(['IS_chr', 'IS_Start', 'IS_End'], keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "adequate-jerusalem",
   "metadata": {},
   "outputs": [],
   "source": [
    "## remove overlap_subTADs from overlap to get the overlap_no_subTADs\n",
    "overlap_no_subTADs = pd.concat([overlap, overlap_subTADs]).drop_duplicates(keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "referenced-physiology",
   "metadata": {},
   "outputs": [],
   "source": [
    "## overlap_IS is using \"overlap\" but not \"overlap_no_subTADs\" to filter because we would like to exculde all \n",
    "#overlepped IS and for those having subTADs we are using the arrowhead TADs results from overlap_subTADs\n",
    "overlap_IS = overlap[['IS_chr', \"IS_Start\", 'IS_End']]\n",
    "df_1 = overlap_IS.drop_duplicates(subset=['IS_chr', \"IS_Start\", 'IS_End'], keep='last').reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "everyday-nutrition",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_IS = pd.read_csv('data/noNA_IS_TAD_containsMaxima.bed', sep='\\t', header = 0)\n",
    "ori_IS.columns = [\"IS_chr\", \"IS_Start\", \"IS_End\", \"IS_TAD_length\"]\n",
    "ori_IS = ori_IS[['IS_chr', \"IS_Start\", 'IS_End']]\n",
    "no_overlap_1 = pd.concat([df_1, ori_IS]).drop_duplicates(keep=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "resistant-cable",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_arrow = overlap[['#chr', \"TAD_start\", 'TAD_end']]\n",
    "df = overlap_arrow.drop_duplicates(subset=['#chr', \"TAD_start\", 'TAD_end'], keep='last').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "smoking-messaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_arrow = pd.read_csv('data/arrow_auto_5000_blocks.bedpe', sep='\\t', header = 0)\n",
    "no_overlap = pd.concat([df, ori_arrow]).drop_duplicates(keep=False)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intelligent-forty",
   "metadata": {},
   "source": [
    "### generate overlap_arrow and overlap_IS to merge in bedtools merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "commercial-selling",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_arrow = overlap_no_subTADs[['#chr', \"TAD_start\", 'TAD_end']]\n",
    "overlap_arrow.columns = ['chr', 'TAD_start', 'TAD_end']\n",
    "overlap_IS = overlap_no_subTADs[['IS_chr', \"IS_Start\", 'IS_End']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "exotic-bernard",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_arrow_IS = pd.concat([overlap_IS, overlap_arrow], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "educated-sucking",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_overlap_arrow_IS_startend = pd.DataFrame({'TAD_Start': np.minimum(overlap_arrow_IS['IS_Start'], overlap_arrow_IS['TAD_start']),\n",
    "                           'TAD_End': np.maximum(overlap_arrow_IS['IS_End'], overlap_arrow_IS['TAD_end'])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "smaller-charm",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_overlap_arrow_IS = pd.concat([overlap_arrow_IS['chr'], merge_overlap_arrow_IS_startend], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "egyptian-costs",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_overlap_arrow_IS.sort_values(by=['chr', 'TAD_Start'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valid-glory",
   "metadata": {},
   "source": [
    "### add no overlap from IS, no overlap from arrow and overlap_subTADs to merged_concat_overlapped_IS_arrow_recip.bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "english-excerpt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arrowhead\n",
    "no_overlap.columns = ['chr', 'TAD_Start', 'TAD_End']\n",
    "# IS\n",
    "no_overlap_1.columns = ['chr', 'TAD_Start', 'TAD_End']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "civil-roommate",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_subTADs_df = overlap_subTADs[['#chr', \"TAD_start\", 'TAD_end']]\n",
    "overlap_subTADs_df.columns = ['chr', 'TAD_Start', 'TAD_End']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "adequate-borough",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-109-88dfbc048ff2>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_TAD_nodup.sort_values(by=['chr', 'TAD_Start', 'TAD_End'], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# to merge all\n",
    "all_TAD = pd.concat([no_overlap_1, no_overlap, overlap_subTADs_df, merge_overlap_arrow_IS])\n",
    "all_TAD.sort_values(by=['chr', 'TAD_Start'], inplace=True)\n",
    "all_TAD_nodup = all_TAD.drop_duplicates()\n",
    "all_TAD_nodup.sort_values(by=['chr', 'TAD_Start', 'TAD_End'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "atlantic-example",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18865, 3)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_TAD_nodup.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.9",
   "language": "python",
   "name": "python3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
