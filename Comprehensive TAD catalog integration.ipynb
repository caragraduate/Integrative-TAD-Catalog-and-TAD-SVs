{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "technical-arrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "printable-syndication",
   "metadata": {},
   "source": [
    "### convert the IS boundary to TAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "handmade-survey",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-d0b062850d1c>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  IS_5kbnew1['IS_start'] = IS_5kbnew1['IS_start']-1\n"
     ]
    }
   ],
   "source": [
    "## auto chr\n",
    "IS_5kb = pd.read_csv('/directory/inter30_5kb.robust_cutoff_boundaries_100kb.bed', sep='\\t', header = None)\n",
    "IS_5kbnew1 = IS_5kb[[0, 1, 2]]\n",
    "IS_5kbnew1.columns = ['chr','IS_start','IS_end']\n",
    "IS_5kbnew1['IS_start'] = IS_5kbnew1['IS_start']-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eligible-egyptian",
   "metadata": {},
   "outputs": [],
   "source": [
    "chr_size = pd.read_csv('/directory/hg38.chrom.sizes_byme', sep='\\t', header = None)\n",
    "invalid = ['chrX', 'chrY', 'chrMT']\n",
    "chr_size_new = chr_size[~chr_size[0].str.contains('|'.join(invalid))].copy()\n",
    "chr_size_new[0] = chr_size_new[0].str.replace('chr','').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fundamental-request",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-f5015843b2f0>:2: FutureWarning: In a future version of pandas, a length 1 tuple will be returned when iterating over a groupby with a grouper equal to a list of length 1. Don't supply a list with a single grouper to avoid this warning.\n",
      "  for k, v in IS_5kbnew1.groupby(['chr']):\n"
     ]
    }
   ],
   "source": [
    "os.chdir('/directory')\n",
    "for k, v in IS_5kbnew1.groupby(['chr']):\n",
    "    v.to_csv(f'IS_boundary_start_end_chr{k}.csv', index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "creative-screening",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range (1,23):\n",
    "    filename = 'IS_boundary_start_end_chr{}.csv'.format(k)\n",
    "    boundary = pd.read_csv(filename, sep=',', header = 0)\n",
    "    boundary = boundary.drop_duplicates()\n",
    "    start = boundary[['chr', 'IS_end']]\n",
    "    start_1 = start.iloc[:-1]\n",
    "    start_1.reset_index(inplace = True, drop = True)\n",
    "    end =  boundary[['IS_start']]\n",
    "    end_1 = end.iloc[1:]\n",
    "    end_1.reset_index(inplace = True, drop = True)\n",
    "    result = pd.concat([start_1, end_1], axis=1)\n",
    "    TAD1_end = boundary.iloc[0]['IS_start'].astype(int)\n",
    "    df2 = pd.DataFrame({'chr': [k], 'IS_end' : ['0'], 'IS_start' : TAD1_end})\n",
    "    TADlast_start = boundary.iloc[-1]['IS_end'].astype(int)\n",
    "    TAD1ast_end = chr_size_new.loc[chr_size_new[0] == k, 1].item()\n",
    "    df3 = pd.DataFrame({'chr': [k], 'IS_end' : TADlast_start, 'IS_start' : TAD1ast_end})\n",
    "    dfnew = pd.concat([df2, result, df3], ignore_index = True, axis = 0)\n",
    "    dfnew.columns = ['chr','TAD_start','TAD_end']\n",
    "    out_file = 'IS_TAD_start_end_chr{}.bed'.format(k)\n",
    "    dfnew.to_csv(out_file, index = False, sep='\\t', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "horizontal-camcorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "root, dirs, files = next(os.walk(os.getcwd()))\n",
    "with open('all_IS_TAD_start_end.bed', 'a') as outfile:\n",
    "    for infile in files:\n",
    "        if infile.startswith('IS_TAD_start'):\n",
    "            df = pd.read_csv(os.path.join(root, infile), sep='\\t', skiprows=[0], header = None)\n",
    "            df = df.drop_duplicates()\n",
    "            df.to_csv(outfile, index=False, sep='\\t', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "central-sterling",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = pd.read_csv('all_IS_TAD_start_end.bed', sep='\\t', header = None)\n",
    "f1new = f1[[0,1,2]]\n",
    "f1new.columns = ['chr','TAD_start','TAD_end']\n",
    "f1new.sort_values(by=['chr', 'TAD_start'], inplace=True)\n",
    "f1new.to_csv('final_IS_TAD_start_end_5kb.bed', index=False, sep='\\t', header = True)\n",
    "f1new['length'] = f1new['TAD_end'] - f1new['TAD_start']\n",
    "f1new.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aware-nation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate minimums in Pandas without `zero`-values\n",
    "f1new_nozero = f1new[(f1new['length'] > 0)]\n",
    "f1new_nozero['length'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "naked-document",
   "metadata": {},
   "outputs": [],
   "source": [
    "## for 5kb:\n",
    "# since min_TAD is 5000bp, which includes 1 bin\n",
    "# we set that exclude if there is any TAD includes >= 1 NA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accurate-voltage",
   "metadata": {},
   "source": [
    "### check if the IS_TAD includes NA insulation score regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "welcome-spank",
   "metadata": {},
   "outputs": [],
   "source": [
    "IS = pd.read_csv('/directory/inter30_5kb.insulation_100kb.bed', sep='\\t', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "hydraulic-superior",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-656ca480b4f2>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ISnew['chr'] = ISnew['chr'].str.replace('chr','')\n",
      "<ipython-input-11-656ca480b4f2>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ISnew['chr'] = ISnew['chr'].astype(str)\n",
      "<ipython-input-11-656ca480b4f2>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ISnew1['chr'] = ISnew1['chr'].astype(int)\n",
      "<ipython-input-11-656ca480b4f2>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ISnew1['IS'] = ISnew1['IS'].astype(str)\n"
     ]
    }
   ],
   "source": [
    "ISnew = IS[[0,1,2,4]]\n",
    "ISnew.columns = ['chr','IS_start','IS_end','IS']\n",
    "ISnew['chr'] = ISnew['chr'].str.replace('chr','')\n",
    "ISnew['chr'] = ISnew['chr'].astype(str)\n",
    "invalid = ['X', 'Y', 'MT']\n",
    "ISnew1 = ISnew[~ISnew['chr'].str.contains('|'.join(invalid))]\n",
    "ISnew1['chr'] = ISnew1['chr'].astype(int)\n",
    "ISnew1['IS'] = ISnew1['IS'].astype(str)\n",
    "IS_NA = ISnew1[ISnew1['IS'] == 'nan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "visible-franchise",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35414, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IS_NA.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grand-hotel",
   "metadata": {},
   "source": [
    "### find if the IS_TAD includes at least 10% of the length of the TADs are NA IS region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "joined-apache",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_chr_na(chr_i):   \n",
    "    filename = 'IS_TAD_start_end_chr{}.bed'.format(chr_i)\n",
    "    TAD = pd.read_csv(filename, sep='\\t', header = 0)\n",
    "    IS_nan = IS_NA[IS_NA.chr == chr_i] \n",
    "    overlap = pd.DataFrame(columns=['chr', 'TAD_start', 'TAD_end', 'IS'])\n",
    "    for start, end in zip(TAD.loc[:, 'TAD_start'], TAD.loc[:, 'TAD_end']):\n",
    "        temp_overlap = IS_nan[IS_nan.loc[:, 'IS_start'].between(start, end) | IS_nan.loc[:, 'IS_end'].between(start, end)]\n",
    "        if temp_overlap.shape[0] >= 1:\n",
    "            temp_overlap2 = temp_overlap.copy(deep = True)\n",
    "            temp_overlap2['chr'] = IS_nan.loc[:, 'chr']\n",
    "            temp_overlap2['TAD_start'] = start\n",
    "            temp_overlap2['TAD_end'] = end\n",
    "            temp_overlap2['IS'] = IS_nan.loc[:, 'IS']\n",
    "            temp_overlap2['num_NA'] = int(temp_overlap.shape[0])\n",
    "            temp_overlap2['num_NA'] = temp_overlap2['num_NA']\n",
    "            overlap = pd.concat([overlap, temp_overlap2], axis=0).astype(str)\n",
    "\n",
    "    ### overlap file\n",
    "    final = overlap[['chr', 'TAD_start', 'TAD_end', 'IS', 'num_NA']].drop_duplicates()\n",
    "    final['length'] = final['TAD_end'].astype(int) - final['TAD_start'].astype(int)\n",
    "    #final['include_NA'] = final['lenth'].astype(int)//5000\n",
    "    out_file = 'NA_TAD_IS_start_end_chr{}.bed'.format(chr_i)\n",
    "    final.to_csv(out_file, index = False, sep='\\t', header=True)\n",
    "    \n",
    "    final_larger = final[final['num_NA'].astype(float).astype(int)*5000 > (final['length']//10).astype(int)]\n",
    "    out_file_1 = 'NA_larger_incluna_TAD_IS_start_end_chr{}.bed'.format(chr_i)\n",
    "    final_larger.to_csv(out_file_1, index = False, sep='\\t', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "daily-attachment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3257 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "all_data = Parallel(n_jobs=40)(delayed(all_chr_na)(chr_i) for chr_i in range(1,23))\n",
    "end = time.time()\n",
    "print('{:.4f} s'.format(end-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpha-degree",
   "metadata": {},
   "source": [
    "### remove the NA_TAD from the all_TAD result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "committed-lighter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_chr_nona(chr_i):   \n",
    "    filename = 'IS_TAD_start_end_chr{}.bed'.format(chr_i)\n",
    "    TAD = pd.read_csv(filename, sep='\\t', header = 0)\n",
    "    filename_1 = 'NA_larger_incluna_TAD_IS_start_end_chr{}.bed'.format(chr_i)\n",
    "    IS_nan = pd.read_csv(filename_1, sep='\\t', header = 0, usecols=range(3))\n",
    "    final = pd.concat([TAD, IS_nan]).drop_duplicates(keep=False)\n",
    "    out_file = 'noNA_TAD_IS_start_end_chr{}.bed'.format(chr_i)\n",
    "    final.to_csv(out_file, index = False, sep='\\t', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "warming-religion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4026 s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "all_data = Parallel(n_jobs=40)(delayed(all_chr_nona)(chr_i) for chr_i in range(1,23))\n",
    "end = time.time()\n",
    "print('{:.4f} s'.format(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "filled-sierra",
   "metadata": {},
   "outputs": [],
   "source": [
    "root, dirs, files = next(os.walk(os.getcwd()))\n",
    "with open('all_noNA_IS_TAD_start_end.bed', 'a') as outfile:\n",
    "    for infile in files:\n",
    "        if infile.startswith('noNA_TAD_IS'):\n",
    "            df = pd.read_csv(os.path.join(root, infile), sep='\\t', skiprows=[0], header = None)\n",
    "            df = df.drop_duplicates()\n",
    "            df.to_csv(outfile, index=False, sep='\\t', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "abstract-biotechnology",
   "metadata": {},
   "outputs": [],
   "source": [
    "f2 = pd.read_csv('all_noNA_IS_TAD_start_end.bed', sep='\\t', header = None)\n",
    "f2new = f2[[0,1,2]]\n",
    "f2new.columns = ['chr','TAD_start','TAD_end']\n",
    "f2new.sort_values(by=['chr', 'TAD_start'], inplace=True)\n",
    "f2new['length'] = f2new['TAD_end'] - f2new['TAD_start']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "brilliant-midwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "### exclude the TAD with zero length\n",
    "f2new_nozero = f2new[(f2new['length'] > 0)]\n",
    "f2new_nozero.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "normal-upset",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7265000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f2new_nozero['length'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "specific-maria",
   "metadata": {},
   "outputs": [],
   "source": [
    "#f2new_nozero.to_csv('final_noNA_IS_TAD_start_end_5kb.bed', index=False, sep='\\t', header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prerequisite-garage",
   "metadata": {},
   "source": [
    "### find the TADs that converted from IS but not having maxima "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "actual-diary",
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_TAD_noNA = pd.read_csv('/directory/chr_final_noNA_IS_TAD_start_end_5kb.bed', sep='\\t')\n",
    "IS_TAD_containMaxima = pd.read_csv('/directory/noNA_IS_TAD_containsMaxima.bed', sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "overall-advice",
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_TAD_containMaxima.columns = ['#chrchr', 'TAD_start', 'TAD_end', 'length']\n",
    "no_maxima = pd.concat([IS_TAD_noNA, IS_TAD_containMaxima]).drop_duplicates(keep=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "other-weapon",
   "metadata": {},
   "source": [
    "### find the TADs that arrowhead detected but IS did not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "editorial-blond",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap = pd.read_csv('/directory/overlap_IS_arrow_new_maxima.bed', sep='\\t', header = None)\n",
    "overlap.columns = [\"IS_chr\", \"IS_Start\", \"IS_End\", \"IS_TAD_length\", \"#chr\", \"TAD_start\", \"TAD_end\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "chief-railway",
   "metadata": {},
   "outputs": [],
   "source": [
    "## retrieve the regions that both arrow and IS detected but arrow has subTADs within it (detected more than one TAD)\n",
    "overlap_subTADs = overlap[overlap.duplicated(['IS_chr', 'IS_Start', 'IS_End'], keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "adequate-jerusalem",
   "metadata": {},
   "outputs": [],
   "source": [
    "## remove overlap_subTADs from overlap to get the overlap_no_subTADs\n",
    "overlap_no_subTADs = pd.concat([overlap, overlap_subTADs]).drop_duplicates(keep=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "referenced-physiology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7740, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## overlap_IS is using \"overlap\" but not \"overlap_no_subTADs\" to filter because we would like to exculde all \n",
    "#overlepped IS and for those having subTADs we are using the arrowhead TADs results from overlap_subTADs\n",
    "overlap_IS = overlap[['IS_chr', \"IS_Start\", 'IS_End']]\n",
    "df_1 = overlap_IS.drop_duplicates(subset=['IS_chr', \"IS_Start\", 'IS_End'], keep='last')\n",
    "df_1.reset_index(inplace = True, drop = True)\n",
    "df_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "everyday-nutrition",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_IS = pd.read_csv('/directory/noNA_IS_TAD_containsMaxima.bed', sep='\\t', header = 0)\n",
    "ori_IS.columns = [\"IS_chr\", \"IS_Start\", \"IS_End\", \"IS_TAD_length\"]\n",
    "ori_IS = ori_IS[['IS_chr', \"IS_Start\", 'IS_End']]\n",
    "no_overlap_1 = pd.concat([df_1, ori_IS]).drop_duplicates(keep=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "resistant-cable",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8902, 3)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overlap_arrow = overlap[['#chr', \"TAD_start\", 'TAD_end']]\n",
    "df = overlap_arrow.drop_duplicates(subset=['#chr', \"TAD_start\", 'TAD_end'], keep='last')\n",
    "df.reset_index(inplace = True, drop = True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "smoking-messaging",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_arrow = pd.read_csv('/directory/arrow_auto_5000_blocks.bedpe', sep='\\t', header = 0)\n",
    "no_overlap = pd.concat([df, ori_arrow]).drop_duplicates(keep=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cheap-equation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3636, 3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_overlap.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intelligent-forty",
   "metadata": {},
   "source": [
    "### generate overlap_arrow and overlap_IS to merge in bedtools merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "commercial-selling",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_arrow = overlap_no_subTADs[['#chr', \"TAD_start\", 'TAD_end']]\n",
    "overlap_arrow.columns = ['chr', 'TAD_start', 'TAD_end']\n",
    "overlap_IS = overlap_no_subTADs[['IS_chr', \"IS_Start\", 'IS_End']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "exotic-bernard",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_arrow_IS = pd.concat([overlap_IS, overlap_arrow], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "educated-sucking",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_overlap_arrow_IS_startend = pd.DataFrame({'TAD_Start': np.minimum(overlap_arrow_IS['IS_Start'], overlap_arrow_IS['TAD_start']),\n",
    "                           'TAD_End': np.maximum(overlap_arrow_IS['IS_End'], overlap_arrow_IS['TAD_end'])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "smaller-charm",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_overlap_arrow_IS = pd.concat([overlap_arrow_IS['chr'], merge_overlap_arrow_IS_startend], axis = 1)\n",
    "merge_overlap_arrow_IS.sort_values(by=['chr', 'TAD_Start'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valid-glory",
   "metadata": {},
   "source": [
    "### add no overlap from IS, no overlap from arrow and overlap_subTADs to merged_concat_overlapped_IS_arrow_recip.bed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "english-excerpt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arrowhead\n",
    "no_overlap.columns = ['chr', 'TAD_Start', 'TAD_End']\n",
    "# IS\n",
    "no_overlap_1.columns = ['chr', 'TAD_Start', 'TAD_End']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "civil-roommate",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap_subTADs_df = overlap_subTADs[['#chr', \"TAD_start\", 'TAD_end']]\n",
    "overlap_subTADs_df.columns = ['chr', 'TAD_Start', 'TAD_End']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "adequate-borough",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-38-88dfbc048ff2>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_TAD_nodup.sort_values(by=['chr', 'TAD_Start', 'TAD_End'], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# to merge all\n",
    "all_TAD = pd.concat([no_overlap_1, no_overlap, overlap_subTADs_df, merge_overlap_arrow_IS])\n",
    "all_TAD.sort_values(by=['chr', 'TAD_Start'], inplace=True)\n",
    "all_TAD_nodup = all_TAD.drop_duplicates()\n",
    "all_TAD_nodup.sort_values(by=['chr', 'TAD_Start', 'TAD_End'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "trying-switzerland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18865, 3)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_TAD_nodup.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expanded-contrary",
   "metadata": {},
   "source": [
    "### check how many subTADs we detected inside the TAD catalog "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fitted-jackson",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_TAD_nodup.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "spectacular-daisy",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-41-db370d05e9a0>:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_TAD_nodup['is_subTAD'] = False\n"
     ]
    }
   ],
   "source": [
    "# Add a new column for indicating if a TAD is a sub-TAD\n",
    "all_TAD_nodup['is_subTAD'] = False\n",
    "\n",
    "# Iterate through the DataFrame, starting from the second row\n",
    "for i in range(1, len(all_TAD_nodup)):\n",
    "    # Get the current and previous rows\n",
    "    current_row = all_TAD_nodup.iloc[i]\n",
    "    previous_row = all_TAD_nodup.iloc[i - 1]\n",
    "\n",
    "    # Check if they are on the same chromosome\n",
    "    if current_row['chr'] == previous_row['chr']:\n",
    "        # Check if the current TAD ends before or at the same position as the previous TAD\n",
    "        if current_row['TAD_End'] <= previous_row['TAD_End']:\n",
    "            all_TAD_nodup.at[i, 'is_subTAD'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "simple-currency",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_TAD_nodup_subTAD = all_TAD_nodup[all_TAD_nodup['is_subTAD'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "induced-cattle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4596, 4)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_TAD_nodup_subTAD.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spoken-integrity",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.9",
   "language": "python",
   "name": "python3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
